---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
head(cars)
```

Graphs that might help us in making a linear regression model:
boxplots
scatterplots 
density plots(to see distribution of the predictor variable)

```{r}
scatter.smooth(x = cars$speed, y = cars$dist, main = "Distance by Speed") #scatterplot
```

Note: one of the underlying assumptions of linear regression is that the relationship between the response and predictor variables is linear and additive

Next, we can use boxplots to check for outliers

In general, an outlier is a datapoint that lies outside the 1.5 IQR

Boxplots
```{r}
par(mfrow = c(1,2))

boxplot(cars$speed, main = "Speed", sub=paste("Outlier rows: ",
   boxplot.stats(cars$speed)$out))

boxplot(cars$dist, main = "Distance", sub=paste("Outlier rows: ",
   boxplot.stats(cars$dist)$out))
```

Using density plot to check if response variable is close to normal(or in other words close to a normal distribution)

```{r}
library(e1071) #for skewness function
par(mfrow = c(1,2)) #divide graph area in two columns

plot(density(cars$speed), main = "Density plot: Speed", 
     ylab = "Frequency", sub = paste("Skewness:", 
                                     round(e1071::skewness(cars$speed))))

polygon(density(cars$speed), col = "red")

plot(density(cars$dist), main = "Density plot: Distance", 
     ylab = "Frequency", sub = paste("Skewness:", 
                                     round(e1071::skewness(cars$dist))))

polygon(density(cars$dist), col = "red")
```

Coorelation analysis: studies the strength of the relationship between two continous variables

- it involves computing the coorelation coefficient between the two variables 

Coorelation: a statistical measure that shows the degree of linear dependence between two variables

- in order to compute coorelation, the two variables must occur in pairs, just like what we did with speed and distance

Coorelation can take values from -1 to +1

If one variable consistentatly increases with the increasing 

Some things to note:
- a value that is closer to 0 indicates a weak relationship 
- a low coorelation (-0.2 < x < 0.2) suggests that much of the variation of the response variable is unexplained by the predictor (X). In this case, you should probably look for explanatory variables.

Coorelation does not mean causation

note: jst because two variables have a high coorelation it does not mean one variable causes the value of another

```{r}
cor(cars$speed, cars$dist)
```

Building the linear relationship model

The function in base R for building linear models is lm()

lm function takes two arguements
- formula
- data

Data is typically a data.frame object and the formula is a object of class formula 

The most common convention is to write out 

The most common convention is to write out the formula as shown below

```{r}
distsplm <- lm(dist~speed, data = cars) ##build linear regression model on full data 

print(distsplm)
```

By doing this regression model, we have established the relationship between the predictor and response in the form of a mathematical formula 

This is distance as a function of speed

From the above output we have two components 

Intercept- 17.579, speed-3.932

Is this enough to use this model? NO!

Before using a linear regression model to make a prediction, you need to make sure it is statistically significant. How do you make sure that this is the case?

```{r}
summary(distsplm)
```

We can use P values to check for statistical significance 

- we can consider a linear model to be statistically significant only when both these p values are less than the pre determined statistical significance value of 0.5

Null and alternative hypothesis 

- Whenever you have a p value, there is always a null and alternate hypothesis 
- What is the null hypothesis in this case

  -In linear regression, the null hypotheis (H0) is that the beta coefficients associated with the variables is equal to 0
  
  -Alternate hypothesis that the coefficients are not equal to 0(i.e. there exists a relationship between the independent and dependent variables)
  
T-values

- A larger value indicates that it is less likely that the coefficient is not equal to 0 by pure chance

- The higher the T-value the better

- Pr(>|t|) is the p-value, or the probability that you get a t-value as high or higher than the observed value when the null hypothesis is equal to 0 (or that there is no relationship)

What does this mean for us?

- when the p-value is less than the significance level of 0.05, you can safely reject the null hypothesis that the coefficient is zero 

- In our case, both of the p-values are well below the 0.05 threshold

- So you can reject the null hypothesis an conclude that the model is indeed statistically significant 

R-Square and Adjusted R-Squared  

- R-squared tells us the proportion of the variation in the dependent(response variable) that has been explained by this model

Adjusted R-Squared 

- So as you add more X variables to your model, the R-squared value of the new bigger model will always be greater than that of the smaller subset

Why?

This is because, since all the variables in the original model are also present, their contribution to explain the dependent variable will be present as well

So unlike R^2 that increases as the number of predictors increase, the adjusted R squared may not always increase

When comparing models it might be good practice to compare using adjusted R-Squared vs regular R-Squared 

Standard error and F statistics 

- both standard error and the F-statisitci are measures of goodness of fit
- the closer to zero the better
- F-statistic the higher the better

AIC(Akaike Information Criterian) and BIC(Bayesian Information Criterian)

Statistic                   Criterion

R-Squared                   higher the better
Adjusted R-squared          higher the better 
F-statistics                higher the better
Standard error              closer to zero is better
T-statistics                should be greater than 1.96 for p-value to be less than 0.05
AIC                         lower the better
BIC                         lower the better

Predicting linear models

If you had to build a linear model by using the whole data set, theres no way to tell how the model will perform with new data 

The preffered practice is to split your data into a 80:20 sample(training set) tjen you will build the model on 80% of your sample, and then use the model to predict the dependent variable on test data 

Doing it this way, we will have the model predicted values for 20% of the data set(what we call the test set) as well as the actuals(from the original data set)

Step 1: Create the training and test data set

```{r}

set.seed(100)

trainindex <- sample(1:nrow(cars), 0.8 * nrow(cars)) #training rows index
traindata <- cars[trainindex,]

traindata <- cars[-trainindex,]
```

Step 2: To fit the model on training data and predict distance on the test data

```{r}

#Build model on training data 

distmd <- lm(dist~speed, data = traindata)
distpd <- predict(distmd, traindata)
```

```{r}
summary(distmd)
```

Step 4: Calucate accuracy and error rates
- A simple coorelation between the actuals and predicted variables can be used as a far more accurate measure
- Higher coorealtion accuracy implies the actuals and predicted values have similar directional movement 
  i.e when the actual value increase the predicted values also increase and vice-versa
  
```{r}
actual_preds <- data.frame(cbind(actuals = traindata$dist,
                                 predicteds = distpd))

coorelation_acc <- cor(actual_preds)

actual_preds

coorelation_acc
```

Calcualte Min Max accuracy 

min_max_accuracy: (mean(min(actuals, predicteds))/mean(actuals, predicteds))

Min Max accuracy will tell us how good of a prediction we have the better the prediction the higher the Min Max will be 

```{r}
min_max_acc <- mean(apply(actual_preds, 1, min)/apply(actual_preds, 1, max))
```

Mean Absolute Percentage Error(MAPE): mean(abs(predicteds, actuals)/(actuals))

```{r}
mape <- mean(abs(actual_preds$predicteds - actual_preds$actuals)/(actual_preds$actuals))

mape
```

Things to consider: RMSE and MSE

k-folds in linear regression

Suppose model predicts satifactorily on the 20% split data, is that enough to believe your model will perform well all the time?

  - it is possible that a few of the data points are not representitve of the population on which the model is built
  
  - For example, in the cars dataset, lets suppose that the cars in the 80% training dataset  were used for road tests on concreate roads but the remaining 20% were used for roadtests on muddy roads
  
If we trained our model with this, you cant expect the model to predict the distance in the test data with equal accuracy, simply because the model has not learned the relationship between speed and distance in such a setting 

It is important yo rigourously test the model performance as much as possible. One way to do this, is to check to see if the model equation performs equally well when trained and tested on different ditinct chunks of data 

This is what k-folds does

1. Splits your data into mutually exclusive random sample portions 
2. Then iteratively builds k models, keeping on the k-subsets as a test data each time 

In each iteration, we build the model on the remaining(k-1 proportion) data and then calculate mean squared error of the predictions on the kth subset

At the end, the average of these mean squared errors is computed

Note: you can use these metrics to compare different linear models 

You need to check two things:

1. If the each of the k-fold model prediction accuracy isnt varying too much for one particular sample 
2. If the lines of the best fit from k-folds dont vary too much with respect to the slope and level

```{r}

```

1. Review the notebook 
2. Jot down questions 
3. Look up the different goodness of fit measures for linear regression models 
4. Look up K-folds

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

